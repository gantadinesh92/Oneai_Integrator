{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##################################################\n",
    "# Library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import psycopg2,os,csv\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import LSTM, Dense, Dropout,Embedding\n",
    "from keras.utils import np_utils,plot_model\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from lxml import etree\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows =100\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "def pickle_(type_):\n",
    "    # Loading the model and dictionary of characters and interger sequence\n",
    "    global model,char_to_integer,integer_to_char,chars,len_input_NN,cat_to_integer,integer_to_cat\n",
    "    pickle_name = 'Models/ML_LCT_'+type_+'_dict.pkl'\n",
    "    pickle_in = open(pickle_name,\"rb\")\n",
    "    pickle_ip_dict = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "\n",
    "    model_file = 'Models/ML_LCT_'+type_+'_Model.h5'\n",
    "    model = load_model(model_file)\n",
    "\n",
    "# # Assigning the variables according to trained model\n",
    "    char_to_integer  = pickle_ip_dict['char_to_integer']\n",
    "    integer_to_char  = pickle_ip_dict['integer_to_char']\n",
    "    chars            = pickle_ip_dict['chars']\n",
    "    len_input_NN     = pickle_ip_dict['len_input_NN']\n",
    "    cat_to_integer   = pickle_ip_dict['cat_to_integer']\n",
    "    integer_to_cat   = pickle_ip_dict['integer_to_cat']\n",
    "\n",
    "\n",
    "# below def generates the values in to a sequence which is understandable by neural network\n",
    "def generate_input_sequence(data_):\n",
    "    data_chr_int =[0]*len_input_NN\n",
    "    i_ = 0 \n",
    "    for char in data_:\n",
    "#         data_chr_int[i_] = char_to_integer[char]\n",
    "        try:\n",
    "            data_chr_int[i_] = char_to_integer[char]\n",
    "        except:\n",
    "            data_chr_int[i_] = 0\n",
    "        if i_ >= len_input_NN-1:\n",
    "            break\n",
    "        i_+=1\n",
    "    data_chr_int = np.reshape(data_chr_int, (1, len_input_NN, 1)) \n",
    "    data_chr_int = data_chr_int/float(len(chars))\n",
    "    return data_chr_int\n",
    "\n",
    "# below def gives the confidence level of each prediction\n",
    "def confident_score(y_pred):\n",
    "    data = [['test1','test1','test1']]\n",
    "    dataframe_ = pd.DataFrame([],columns=['index','value','column'])\n",
    "    dataframe_\n",
    "    for index,i in enumerate(y_pred[0],start=0):\n",
    "        if index == 54:\n",
    "            break\n",
    "        data = {'index':index,'value':round(i*100,2),'column':integer_to_cat[index]}\n",
    "        dataframe_ = dataframe_.append(data,ignore_index=True)    \n",
    "\n",
    "    dataframe_ = dataframe_.sort_values(by=['value'],ascending=False)\n",
    "    return dataframe_\n",
    "\n",
    "# Predicting the input_sequence value to a index\n",
    "def predict_(input_sequence):\n",
    "    X_input = np.reshape(input_sequence, (1, len(input_sequence), 1))\n",
    "    y_pred = model.predict(X_input, verbose=0)\n",
    "    index = np.argmax(y_pred)\n",
    "#     print(index,integer_to_cat[index])\n",
    "    return y_pred,index,integer_to_cat[index]\n",
    "\n",
    "\n",
    "# Processing XML file to predic the values and give the confidence score to each value\n",
    "\n",
    "def etree_iter_path(node, tag=None, path='.'):\n",
    "    if tag == \"*\":\n",
    "        tag = None\n",
    "    if tag is None or node.tag == tag:\n",
    "        yield node, path\n",
    "    for child in node:\n",
    "        _child_path = '%s/%s' % (path, child.tag)\n",
    "        for child, child_path in etree_iter_path(child, tag, path=_child_path):\n",
    "            yield child, child_path\n",
    "\n",
    "def tree_struct_orginal(file): \n",
    "       \n",
    "    tree = ElementTree.parse(file)\n",
    "    root = tree.getroot()    \n",
    "\n",
    "    orginal_path_ = []\n",
    "    xmldoc = ElementTree.parse(file)\n",
    "    for elem, path in etree_iter_path(xmldoc.getroot()):\n",
    "        orginal_path_.append(path)\n",
    "\n",
    "    key_value_ = []\n",
    "    for i in root.iter():\n",
    "        key_value_.append([i.tag,i.text])\n",
    "\n",
    "    final_ =[]\n",
    "    for index,value in enumerate(orginal_path_):\n",
    "        final_.append([value,key_value_[index][1]])       \n",
    "\n",
    "    result_ = []\n",
    "    for i in final_:\n",
    "        if type(i[1]) != type(None) and '\\n\\t' not in i[1]:\n",
    "            result_.append(i) \n",
    "    result_values_ = []\n",
    "    for i in result_:\n",
    "        result_values_.append(i[1])    \n",
    "       \n",
    "    return result_values_,result_ \n",
    "\n",
    "def csv_to_DB(df):\n",
    "    test_df  = pd.DataFrame()\n",
    "    test_df1 = pd.DataFrame()\n",
    "\n",
    "    test_df['data']   = df[df.columns[0]].replace(\"'\",\"\").astype(str)\n",
    "    test_df['result'] = df.columns[0] #[test.columns[0],test.columns[0]] \n",
    "\n",
    "    for i in df.columns[1:]:\n",
    "        test_df1['data'] = df[i].astype(str).str.replace(\"'\",\"\")\n",
    "        test_df = test_df.append(test_df1,ignore_index=True)\n",
    "        test_df.result.fillna(i.replace(\" \", \"_\"),inplace=True)\n",
    "    test_df = test_df[test_df.data!='nan']\n",
    "    test_df = test_df.rename(columns={'result': 0,'data':1})\n",
    "    return test_df\n",
    "\n",
    "def get_xml(file_name):\n",
    "    file_name = 'TestCase/'+file_name\n",
    "\n",
    "    df = pd.DataFrame(tree_struct_orginal(file_name)[1])\n",
    "    df =df[~df[0].str.contains(\"{\")]\n",
    "    df['Predicted_Values']=''\n",
    "    df['Confidence_Score']=''\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        row['Predicted_Values'] = predict_(generate_input_sequence(row[1])[0])[2] # put the predicted interval value \n",
    "        row['Confidence_Score'] = confident_score(predict_(generate_input_sequence(row[1])[0])[0]).reset_index()['value'][0]# put that logic to give confidence interval\n",
    "    \n",
    "    list_ = df.Predicted_Values.unique()\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1 = pd.DataFrame(columns=[0,1,'Predicted_Values','Confidence_Score'])\n",
    "    \n",
    "    for i in list_:\n",
    "        df1 = df1.append(df[df['Predicted_Values']==i].sort_values('Confidence_Score',ascending=False))\n",
    "    return df1\n",
    "\n",
    "def get_csv(file_name):\n",
    "    file_name = 'TestCase/'+file_name\n",
    "\n",
    "    df = csv_to_DB(pd.read_csv(file_name))\n",
    "\n",
    "    df =df[~df[0].str.contains(\"{\")]\n",
    "    df['Predicted_Values']=''\n",
    "    df['Confidence_Score']=''\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        row['Predicted_Values'] = predict_(generate_input_sequence(row[1])[0])[2] # put the predicted interval value \n",
    "        row['Confidence_Score'] = confident_score(predict_(generate_input_sequence(row[1])[0])[0]).reset_index()['value'][0]# put that logic to give confidence interval\n",
    "    \n",
    "    list_ = df.Predicted_Values.unique()\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1 = pd.DataFrame(columns=[0,1,'Predicted_Values','Confidence_Score'])\n",
    "    \n",
    "    for i in list_:\n",
    "        df1 = df1.append(df[df['Predicted_Values']==i].sort_values('Confidence_Score',ascending=False))\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5003/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Jul/2020 22:15:05] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Jul/2020 22:15:06] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_x.xml location save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Jul/2020 22:15:31] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, session, redirect\n",
    "### working code -- which displays the DataFrame\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('Predict/ONEai.html')\n",
    "\n",
    "@app.route('/', methods=(\"POST\", \"GET\"))\n",
    "def html_table():\n",
    "    file_name = request.form['myfile']\n",
    "    type_ = request.form['type_']\n",
    "    save_ = request.form['save_']\n",
    "    print(file_name,type_,save_)\n",
    "    pickle_(type_)\n",
    "    if '.xml' in file_name:\n",
    "        data_frame = get_xml(file_name)\n",
    "        data_frame = data_frame.rename(columns={0: 'X_Path',1:'Value'})\n",
    "        if save_ == 'save':\n",
    "            data_frame.to_csv('Saved_Mapping/'+type_+'.csv')\n",
    "        return render_template('Predict/Predict_Confidence.html',  tables=[data_frame.to_html(classes='data')], tables1=[data_frame.groupby([\"Predicted_Values\"]).first().to_html(classes='data')])\n",
    "    elif '.csv' in file_name:\n",
    "        data_frame = get_csv(file_name)\n",
    "        data_frame = data_frame.rename(columns={0: 'Column',1:'Value'})\n",
    "        if save_ == 'save':\n",
    "            data_frame.to_csv('Saved_Mapping/'+type_+'.csv')\n",
    "        return render_template('Predict/Predict_Confidence.html',  tables=[data_frame.to_html(classes='data')], tables1=[data_frame.groupby([\"Predicted_Values\"]).first().to_html(classes='data')])\n",
    "\n",
    "@app.route('/value')\n",
    "def my_form1():\n",
    "    return render_template('Predict/value.html')\n",
    "\n",
    "@app.route('/value', methods=(\"POST\", \"GET\"))\n",
    "def html_table1():\n",
    "    Input = request.form['value_']\n",
    "    print(\"Input :\" +Input)\n",
    "    input_sequence = generate_input_sequence(Input)[0]\n",
    "    # print(input_sequence)\n",
    "    y_pred = predict_(input_sequence)\n",
    "    data_frame = confident_score(y_pred[0])\n",
    "    return render_template('Predict/value_confidence.html',  tables=[data_frame.to_html(classes='data')])\n",
    "\n",
    "@app.route('/data')\n",
    "def my_form2():\n",
    "    return render_template('DataStructure/DataStructure_Home.html')\n",
    "\n",
    "@app.route('/data', methods=(\"POST\", \"GET\"))\n",
    "def html_table2():\n",
    "    filename = request.form['myfile']\n",
    "#     print(filename)\n",
    "    filename = 'TestCase/'+filename\n",
    "    print(filename)\n",
    "    \n",
    "    if '.xml' in filename:\n",
    "        print(\"ener\")\n",
    "        df = pd.DataFrame(tree_struct_orginal(filename)[1])\n",
    "        df =df[~df[0].str.contains(\"{\")]\n",
    "        df = df.rename(columns={0: 'X_Path',1:'Value'})\n",
    "        return render_template('DataStructure/Result.html',  tables=[df.to_html(classes='data')], titles=df.columns.values)\n",
    "    elif '.csv' in filename:\n",
    "        df = csv_to_DB(pd.read_csv(filename))\n",
    "        df = df.rename(columns={0: 'Column',1:'Value'})\n",
    "        return render_template('DataStructure/Result.html',  tables=[df.to_html(classes='data')], titles=df.columns.values)\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app.run(host = '127.0.0.1', port='5003',threaded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # For Testing Purpuse\n",
    "# Input = \"dallas \"\n",
    "# print(\"Input :\" +Input)\n",
    "# input_sequence = generate_input_sequence(Input)[0]\n",
    "# # print(input_sequence)\n",
    "# y_pred = predict_(input_sequence)\n",
    "# confident_score(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data_frame.to_html(classes='data')\n",
    "\n",
    "# below def generates the values which is understandble by human from a nueral network sequence\n",
    "# def generate_output_sequence(input_sequence):\n",
    "#     Test_char = []\n",
    "#     for i in input_sequence:\n",
    "#         if i == 0:\n",
    "#             break\n",
    "#         Test_char.append(integer_to_char[round(list(i*len(chars))[0],0)])\n",
    "#     Test_char = ''.join(Test_char)\n",
    "#     return Test_char  \n",
    "# generate_output_sequence(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_(type_)\n",
    "# test_data_frame =get_xml('ADD_Location_NEW_LOCATION07_ID175Y481C.xml')\n",
    "# test_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_ = 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_xml(file_name):\n",
    "#     file_name = 'TestCase/'+file_name\n",
    "\n",
    "# #     filename = 'TestCase/ADD_Location_NEW_LOCATION07_ID175Y481C.xml'\n",
    "#     df = pd.DataFrame(tree_struct_orginal(file_name)[1])\n",
    "#     df =df[~df[0].str.contains(\"{\")]\n",
    "#     df['Predicted_Values']=''\n",
    "#     df['Confidence_Score']=''\n",
    "\n",
    "#     for index, row in df.iterrows():\n",
    "#         row['Predicted_Values'] = predict_(generate_input_sequence(row[1])[0])[2] # put the predicted interval value \n",
    "#         row['Confidence_Score'] = confident_score(predict_(generate_input_sequence(row[1])[0])[0]).reset_index()['value'][0]# put that logic to give confidence interval\n",
    "    \n",
    "#     list_ = df.Predicted_Values.unique()\n",
    "\n",
    "#     df1 = pd.DataFrame()\n",
    "#     df1 = pd.DataFrame(columns=[0,1,'Predicted_Values','Confidence_Score'])\n",
    "    \n",
    "#     for i in list_:\n",
    "#         df1 = df1.append(df[df['Predicted_Values']==i].sort_values('Confidence_Score',ascending=False))\n",
    "#     return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_xml('ADD_Location_NEW_LOCATION07_ID175Y481C.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, render_template, session, redirect\n",
    "# ### working code -- which displays the DataFrame\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/')\n",
    "# def my_form():\n",
    "#     return render_template('ONEai.html')\n",
    "\n",
    "# @app.route('/', methods=(\"POST\", \"GET\"))\n",
    "# def html_table():\n",
    "#     filename = request.form['myfile']\n",
    "#     print(filename)\n",
    "# # #     print(filename)\n",
    "# #     filename = 'TestCase/'+filename\n",
    "# #     print(filename)\n",
    "# #     df = pd.DataFrame(tree_struct_orginal(filename)[1])\n",
    "# #     df =df[~df[0].str.contains(\"{\")]\n",
    "#     data_frame = get_xml(file_name)\n",
    "#     data_frame = data_frame.rename(columns={0: 'X_Path',1:'Value'})\n",
    "\n",
    "#     return render_template('Predict_Confidence.html',  tables=[data_frame.to_html(classes='data')], titles=df.columns.values)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.DataFrame()\n",
    "\n",
    "# df_test['col1']=''\n",
    "# df_test['col2']=''\n",
    "\n",
    "# # df_test.insert('1','2')\n",
    "# df_test.insert(0, 'col1',\"1\")\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filename = 'TestCase/ADD_Location_NEW_LOCATION07_ID175Y481C.xml'\n",
    "# # TestCase/ADD_Location_NEW_LOCATION07_ID175Y481C.xml\n",
    "# # filename = request.form['myfile']\n",
    "# # print(filename)\n",
    "# # filename = 'TestCase/'+filename\n",
    "# # print(filename)\n",
    "# df = pd.DataFrame(tree_struct_orginal(filename)[1])\n",
    "# df =df[~df[0].str.contains(\"{\")]\n",
    "# df['Predicted_Values']=''\n",
    "# df['Confidence_Score']=''\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for index, row in df.iterrows():\n",
    "#     row['Predicted_Values'] = predict_(generate_input_sequence(row[1])[0])[2] # put the predicted interval value \n",
    "#     row['Confidence_Score'] = confident_score(predict_(generate_input_sequence(row[1])[0])[0]).reset_index()['value'][0]# put that logic to give confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(row[1])\n",
    "# print(generate_input_sequence(row[1])[0])\n",
    "# confident_score(predict_(generate_input_sequence(row[1])[0])[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_ = df.Predicted_Values.unique()\n",
    "\n",
    "# df1 = pd.DataFrame()\n",
    "# df1 = pd.DataFrame(columns=[0,1,'Predicted_Values','Confidence_Score'])\n",
    "\n",
    "# for i in list_:\n",
    "#     df1 = df1.append(df[df['Predicted_Values']==i].sort_values('Confidence_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'ADD_Location_NEW_LOCATION07_ID175Y481C.xml'\n",
    "# get_xml(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
