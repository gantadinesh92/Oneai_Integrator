{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i am in library start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i am in library end\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "#Library\n",
    "print(\" i am in library start\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2,os,csv\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout,Embedding\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    " \n",
    "from pickle import dump\n",
    "import pickle\n",
    "print(\" i am in library end\")\n",
    "\n",
    "len_input_NN = 30  #this determined the number of Input to the nueral network model\n",
    "#######################################################\n",
    "def train_model(type_):\n",
    "\n",
    "    #Connecting to Database\n",
    "    print(\" i am in connection database start\")\n",
    "    conn = psycopg2.connect(\"dbname=postgres user=postgres password=Msjobs@123\")\n",
    "\n",
    "    def select_data(type_):\n",
    "        cur = conn.cursor()\n",
    "        sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ ='\" +type_+\"';\"\n",
    "    #     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ = 'location';\"\n",
    "        data = pd.read_sql(sql_command, conn)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        return data  \n",
    "\n",
    "    #Renaming the columns\n",
    "    # type_ = 'location'\n",
    "    test_df = select_data(type_).rename(columns={\"value_\": \"data\",\"key_\": \"result\"})\n",
    "    print(\" i am in connection database end\")\n",
    "    #####################################################\n",
    "    # Handling varity of characters in the upcoming inputs\n",
    "    print(\" i am in char_num building start\")\n",
    "#     listchars_ = ' \"abcdefghijklmnopqrstvuwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890-=+_`~[]{}\\|:;,.<>?/!@#$%^&*()ïáúãüóíéñÁäöôàÉ'\n",
    "    listchars_ = ' \"abcdefghijklmnopqrstvuwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890-=+_`~[]{}\\|:;,.<>?/!@#$%^&*()'\n",
    "    chars = sorted(list(set(listchars_)))\n",
    "\n",
    "    char_to_integer = []\n",
    "    for integer, char in enumerate(chars,start=1):\n",
    "        char_to_integer.append((char, integer))\n",
    "    char_to_integer = dict(char_to_integer)\n",
    "\n",
    "    integer_to_char = []\n",
    "    for integer, char in enumerate(chars,start=1):\n",
    "        integer_to_char.append((integer,char))\n",
    "    integer_to_char = dict(integer_to_char)\n",
    "    print(\" i am in char_num building end\")\n",
    "    #####################################################\n",
    "    # Assigning Numeric to all the values\n",
    "    print(\" i am in assigning start\")\n",
    "#     len_input_NN = 30  #this determined the number of Input to the nueral network model\n",
    "    test_df[\"data_int\"]= \"\"\n",
    "\n",
    "    for i in range(0, (len(test_df.data))):\n",
    "        data_chr_int =[0]*len_input_NN\n",
    "        data_ = str(test_df.data[i])\n",
    "        i_ = 0 \n",
    "        for char in data_:\n",
    "            try:\n",
    "                data_chr_int[i_] = char_to_integer[char]\n",
    "            except:\n",
    "                data_chr_int[i_] = 0\n",
    "            if i_ >= len_input_NN-1:\n",
    "                break\n",
    "            i_+=1\n",
    "        test_df[\"data_int\"][i] = data_chr_int\n",
    "    print(\" i am in assigning end\")\n",
    "\n",
    "    #####################################################\n",
    "    print(\" i am in category start\")\n",
    "    # Assigning the category to index and index to category for predicting the category in future using index\n",
    "    result_char = (list(set(test_df.result)))\n",
    "    cat_to_integer = []\n",
    "    integer_to_cat = []\n",
    "\n",
    "    for integer, char in enumerate(result_char,start=0):\n",
    "        cat_to_integer.append((char, integer))\n",
    "    cat_to_integer = dict(cat_to_integer)\n",
    "\n",
    "    for integer, char in enumerate(result_char,start=0):\n",
    "        integer_to_cat.append((integer, char))\n",
    "    integer_to_cat = dict(integer_to_cat)\n",
    "\n",
    "    test_df[\"result_int\"] = \"\"\n",
    "    for i in range(0, (len(test_df.result))):\n",
    "        test_df[\"result_int\"][i] = cat_to_integer[test_df['result'][i]]\n",
    "    print(\" i am in category end\")\n",
    "\n",
    "    #####################################################\n",
    "    print(\" i am in preparing start\")\n",
    "    # Preparing the data for the Nueral Network model \n",
    "    X_train =[]\n",
    "\n",
    "    for i in test_df.data_int:\n",
    "        X_train.append(i)\n",
    "\n",
    "    # Reshape X_train and normalize\n",
    "    X_train = np.reshape(X_train, (len(X_train), len_input_NN, 1)) \n",
    "    X_train = X_train/float(len(chars))\n",
    "    y_train = np_utils.to_categorical(test_df.result_int)\n",
    "    print(\" i am in preparing end\")\n",
    "\n",
    "    #####################################################\n",
    "    # Model\n",
    "    print(\"i am in model start\")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape = (X_train.shape[1], X_train.shape[2]))) # 256 hidden nodes\n",
    "    model.add(Dropout(0.2))#This technique is applied in the training phase to reduce overfitting effects.# https://www.python-course.eu/neural_networks_with_dropout.php\n",
    "    model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs = 50, batch_size = 2000)\n",
    "    print(\"i am in model end\")\n",
    "    ######################################################\n",
    "    # Saving the model \n",
    "    print(\"i am in saving model start\")\n",
    "    pickle_op_dict = dict()\n",
    "    pickle_op_dict['char_to_integer']= char_to_integer\n",
    "    pickle_op_dict['integer_to_char']= integer_to_char\n",
    "    pickle_op_dict['chars']          = chars\n",
    "    pickle_op_dict['len_input_NN']   = len_input_NN\n",
    "    pickle_op_dict['integer_to_cat'] = integer_to_cat\n",
    "    pickle_op_dict['cat_to_integer'] = cat_to_integer\n",
    "    pickle_dict = 'Models/ML_LCT_'+type_+'_dict.pkl'\n",
    "    pickle_out = open(pickle_dict,\"wb\")\n",
    "    pickle.dump(pickle_op_dict, pickle_out)\n",
    "    pickle_out.close()\n",
    "    print(\"saved pickle\")\n",
    "    model_file= 'Models/ML_LCT_'+type_+'_Model.h5'\n",
    "    model.save(model_file)\n",
    "    print('i am in saving model end')\n",
    "    return (test_df,X_train,model,integer_to_cat)\n",
    "\n",
    "#################################################\n",
    "# Model Accuracy \n",
    "def pred_(Input,model):\n",
    "    X_input = np.reshape(Input, (1, len_input_NN, 1))\n",
    "    y_pred = model.predict(X_input, verbose=0)\n",
    "    return np.argmax(y_pred)\n",
    "def model_accuracy(test_df,X_train,model):\n",
    "    df_ = test_df.copy()\n",
    "    df_['pred']=''\n",
    "    # test1.head()\n",
    "\n",
    "    for index,value in enumerate(X_train):\n",
    "        df_['pred'][index] = pred_(value,model)\n",
    "    return df_\n",
    "\n",
    "def generate_report(type_):\n",
    "    data_ = train_model(type_)\n",
    "    test_df = data_[0]\n",
    "    X_train = data_[1]\n",
    "    model = data_[2]\n",
    "    integer_to_cat = data_[3]\n",
    "    df_ = model_accuracy(test_df,X_train,model)\n",
    "    target_names =[]\n",
    "    for key_,value_ in integer_to_cat.items():\n",
    "        target_names.append(value_)\n",
    "\n",
    "    report = classification_report(list(df_['result_int']), list(df_['pred']),target_names=target_names, output_dict=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.2:5002/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Jul/2020 17:23:34] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i am in connection database start\n",
      " i am in connection database end\n",
      " i am in char_num building start\n",
      " i am in char_num building end\n",
      " i am in assigning start\n",
      " i am in assigning end\n",
      " i am in category start\n",
      " i am in category end\n",
      " i am in preparing start\n",
      " i am in preparing end\n",
      "i am in model start\n",
      "Epoch 1/50\n",
      "6897/6897 [==============================] - 2s 327us/step - loss: 0.2447 - accuracy: 0.9333\n",
      "Epoch 2/50\n",
      "6897/6897 [==============================] - 1s 201us/step - loss: 0.2433 - accuracy: 0.9333\n",
      "Epoch 3/50\n",
      "6897/6897 [==============================] - 1s 201us/step - loss: 0.2375 - accuracy: 0.9336\n",
      "Epoch 4/50\n",
      "6897/6897 [==============================] - 1s 201us/step - loss: 0.2299 - accuracy: 0.9334\n",
      "Epoch 5/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.2180 - accuracy: 0.9331\n",
      "Epoch 6/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.2126 - accuracy: 0.9328\n",
      "Epoch 7/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.2049 - accuracy: 0.9334\n",
      "Epoch 8/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1971 - accuracy: 0.9336\n",
      "Epoch 9/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1905 - accuracy: 0.9334\n",
      "Epoch 10/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1777 - accuracy: 0.9335\n",
      "Epoch 11/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1699 - accuracy: 0.9339\n",
      "Epoch 12/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1634 - accuracy: 0.9333\n",
      "Epoch 13/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1574 - accuracy: 0.9336\n",
      "Epoch 14/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1512 - accuracy: 0.9356\n",
      "Epoch 15/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1460 - accuracy: 0.9378\n",
      "Epoch 16/50\n",
      "6897/6897 [==============================] - 1s 203us/step - loss: 0.1478 - accuracy: 0.9373\n",
      "Epoch 17/50\n",
      "6897/6897 [==============================] - 1s 203us/step - loss: 0.1433 - accuracy: 0.9383\n",
      "Epoch 18/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1393 - accuracy: 0.9387\n",
      "Epoch 19/50\n",
      "6897/6897 [==============================] - 1s 203us/step - loss: 0.1354 - accuracy: 0.9410\n",
      "Epoch 20/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1325 - accuracy: 0.9417\n",
      "Epoch 21/50\n",
      "6897/6897 [==============================] - 1s 202us/step - loss: 0.1394 - accuracy: 0.9390\n",
      "Epoch 22/50\n",
      "6897/6897 [==============================] - 1s 204us/step - loss: 0.1385 - accuracy: 0.9398\n",
      "Epoch 23/50\n",
      "6897/6897 [==============================] - 1s 207us/step - loss: 0.1338 - accuracy: 0.9404\n",
      "Epoch 24/50\n",
      "6897/6897 [==============================] - 1s 207us/step - loss: 0.1305 - accuracy: 0.9419\n",
      "Epoch 25/50\n",
      "6897/6897 [==============================] - 1s 207us/step - loss: 0.1285 - accuracy: 0.9420\n",
      "Epoch 26/50\n",
      "6897/6897 [==============================] - 1s 207us/step - loss: 0.1276 - accuracy: 0.9426\n",
      "Epoch 27/50\n",
      "6897/6897 [==============================] - 1s 207us/step - loss: 0.1285 - accuracy: 0.9427\n",
      "Epoch 28/50\n",
      "6897/6897 [==============================] - 1s 206us/step - loss: 0.1246 - accuracy: 0.9446\n",
      "Epoch 29/50\n",
      "6897/6897 [==============================] - 1s 210us/step - loss: 0.1209 - accuracy: 0.9476\n",
      "Epoch 30/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1279 - accuracy: 0.9430\n",
      "Epoch 31/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1369 - accuracy: 0.9403\n",
      "Epoch 32/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1375 - accuracy: 0.9399\n",
      "Epoch 33/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1300 - accuracy: 0.9422\n",
      "Epoch 34/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1236 - accuracy: 0.9448\n",
      "Epoch 35/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1224 - accuracy: 0.9452\n",
      "Epoch 36/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1189 - accuracy: 0.9472\n",
      "Epoch 37/50\n",
      "6897/6897 [==============================] - 1s 211us/step - loss: 0.1157 - accuracy: 0.9486\n",
      "Epoch 38/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1128 - accuracy: 0.9493\n",
      "Epoch 39/50\n",
      "6897/6897 [==============================] - 1s 214us/step - loss: 0.1097 - accuracy: 0.9499\n",
      "Epoch 40/50\n",
      "6897/6897 [==============================] - 1s 214us/step - loss: 0.1061 - accuracy: 0.9507\n",
      "Epoch 41/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1404 - accuracy: 0.9409\n",
      "Epoch 42/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1483 - accuracy: 0.9386\n",
      "Epoch 43/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1327 - accuracy: 0.9406\n",
      "Epoch 44/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1189 - accuracy: 0.9478\n",
      "Epoch 45/50\n",
      "6897/6897 [==============================] - 1s 212us/step - loss: 0.1123 - accuracy: 0.9484\n",
      "Epoch 46/50\n",
      "6897/6897 [==============================] - 1s 213us/step - loss: 0.1097 - accuracy: 0.9485\n",
      "Epoch 47/50\n",
      "6897/6897 [==============================] - 1s 213us/step - loss: 0.1069 - accuracy: 0.9508\n",
      "Epoch 48/50\n",
      "6897/6897 [==============================] - 1s 214us/step - loss: 0.1141 - accuracy: 0.9467\n",
      "Epoch 49/50\n",
      "6897/6897 [==============================] - 1s 213us/step - loss: 0.1111 - accuracy: 0.9488\n",
      "Epoch 50/50\n",
      "6897/6897 [==============================] - 1s 213us/step - loss: 0.1052 - accuracy: 0.9502\n",
      "i am in model end\n",
      "i am in saving model start\n",
      "saved pickle\n",
      "i am in saving model end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Jul/2020 17:28:01] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, session, redirect\n",
    "### working code -- which displays the DataFrame\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('Train_ML_Report_index.html')\n",
    "\n",
    "@app.route('/', methods=(\"POST\", \"GET\"))\n",
    "def html_table():\n",
    "    K.clear_session()\n",
    "\n",
    "#     type_ = 'location'\n",
    "    type_ = request.form['schemas_']\n",
    "    data_frame = pd.DataFrame(generate_report(type_)).transpose()\n",
    "\n",
    "    return render_template('Train_ML_Report.html',  tables=[data_frame.to_html(classes='data')])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host = '127.0.0.2', port='5002',threaded=False) # host = '127.0.0.2', port='5002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect(\"dbname=postgres user=postgres password=Msjobs@123\")\n",
    "# type_='location'\n",
    "# def select_data(type_):\n",
    "#     cur = conn.cursor()\n",
    "#     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ ='\" +type_+\"';\"\n",
    "#     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ = 'location';\"\n",
    "\n",
    "#     data = pd.read_sql(sql_command, conn)\n",
    "#     conn.commit()\n",
    "#     cur.close()\n",
    "#     return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Renaming the columns\n",
    "# # type_ = 'location'\n",
    "# test_df = select_data(type_).rename(columns={\"value_\": \"data\",\"key_\": \"result\"})\n",
    "# print(\" i am in connection database end\")\n",
    "# #####################################################\n",
    "# # Handling varity of characters in the upcoming inputs\n",
    "# print(\" i am in char_num building start\")\n",
    "# listchars_ = ' \"klmnopqrstvuwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890-=+_`~[]{}\\|:;,.<>?/!@#$%^&*()ïáúãüóíéñÁäöôàÉ'\n",
    "# chars = sorted(list(set(listchars_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_to_integer = []\n",
    "# for integer, char in enumerate(chars,start=1):\n",
    "#     char_to_integer.append((char, integer))\n",
    "# char_to_integer = dict(char_to_integer)\n",
    "\n",
    "# integer_to_char = []\n",
    "# for integer, char in enumerate(chars,start=1):\n",
    "#     integer_to_char.append((integer,char))\n",
    "# integer_to_char = dict(integer_to_char)\n",
    "# print(\" i am in char_num building end\")\n",
    "# #####################################################\n",
    "# # Assigning Numeric to all the values\n",
    "# print(\" i am in assigning start\")\n",
    "# len_input_NN = 30  #this determined the number of Input to the nueral network model\n",
    "# test_df[\"data_int\"]= \"\"\n",
    "\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, (len(test_df.data))):\n",
    "#     data_chr_int =[0]*len_input_NN\n",
    "#     data_ = str(test_df.data[i])\n",
    "#     i_ = 0 \n",
    "#     for char in data_:\n",
    "#         data_chr_int[i_] = char_to_integer[char]\n",
    "#         if i_ >= len_input_NN-1:\n",
    "#             break\n",
    "#         i_+=1\n",
    "#     test_df[\"data_int\"][i] = data_chr_int\n",
    "# print(\" i am in assigning end\")\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_chr_int =[0]*30\n",
    "# i_=0\n",
    "# for i in \"dinesh\":\n",
    "#     try:\n",
    "#         data_chr_int[i_] = char_to_integer[i]\n",
    "#     except :\n",
    "#         data_chr_int[i_] = 0\n",
    "#     print(i)\n",
    "#     if i_ >= 30-1:\n",
    "#             break\n",
    "#     i_+=1\n",
    "# data_chr_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_input_sequence(data_):\n",
    "#     data_chr_int =[0]*len_input_NN\n",
    "#     i_ = 0 \n",
    "#     for char in data_:\n",
    "#         data_chr_int[i_] = char_to_integer[char]\n",
    "#         if i_ >= len_input_NN-1:\n",
    "#             break\n",
    "#         i_+=1\n",
    "#     data_chr_int = np.reshape(data_chr_int, (1, len_input_NN, 1)) \n",
    "#     data_chr_int = data_chr_int/float(len(chars))\n",
    "#     return data_chr_int\n",
    "# # generate_input_sequence(\"dinesh\")\n",
    "\n",
    "# def generate_output_sequence(input_sequence):\n",
    "#     Test_char = []\n",
    "#     for i in input_sequence:\n",
    "#         if i == 0:\n",
    "#             break\n",
    "#         Test_char.append(integer_to_char[round(list(i*len(chars))[0],0)])\n",
    "#     Test_char = ''.join(Test_char)\n",
    "#     return Test_char   \n",
    "# # generate_output_sequence(input_sequence)\n",
    "\n",
    "# def generate_random_sequence():\n",
    "#     random_number = np.random.randint(0, len(X_train)-1)\n",
    "#     input_sequence = X_train[random_number]\n",
    "#     return input_sequence\n",
    "# #     print(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_number = np.random.randint(0, len(X_train)-1)\n",
    "# input_sequence = X_train[random_number]\n",
    "# print(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_sequence = generate_input_sequence(\"23\")[0]\n",
    "# input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_output_sequence(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input for this file is Type so that it will generate the model which is required accordingly can be used for reinforcement of the ML model in the architecture\n",
    "# type_ = 'location'\n",
    "# %%time\n",
    "# #####################################################\n",
    "# #Library\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import psycopg2,os,csv\n",
    "\n",
    "# from IPython.display import display\n",
    "# pd.options.display.max_columns = None\n",
    "\n",
    "# from keras import backend as K\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Dropout,Embedding\n",
    "# from keras.utils import np_utils\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# from pickle import dump\n",
    "# import pickle\n",
    "# #######################################################\n",
    "# #Connecting to Database\n",
    "# conn = psycopg2.connect(\"dbname=postgres user=postgres password=Msjobs@123\")\n",
    "\n",
    "# def select_data(type_):\n",
    "#     cur = conn.cursor()\n",
    "#     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ ='\" +type_+\"';\"\n",
    "# #     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ = 'location';\"\n",
    "#     data = pd.read_sql(sql_command, conn)\n",
    "#     conn.commit()\n",
    "#     cur.close()\n",
    "#     return data  \n",
    "\n",
    "# #Renaming the columns\n",
    "# # type_ = 'location'\n",
    "# test_df = select_data(type_).rename(columns={\"value_\": \"data\",\"key_\": \"result\"})\n",
    "\n",
    "# #####################################################\n",
    "# # Handling varity of characters in the upcoming inputs\n",
    "# listchars_ = ' \"abcdefghijklmnopqrstvuwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890-=+_`~[]{}\\|:;,.<>?/!@#$%^&*()áúãüóíéñÁäöôàÉ'\n",
    "# chars = sorted(list(set(listchars_)))\n",
    "\n",
    "# char_to_integer = []\n",
    "# for integer, char in enumerate(chars,start=1):\n",
    "#     char_to_integer.append((char, integer))\n",
    "# char_to_integer = dict(char_to_integer)\n",
    "\n",
    "# integer_to_char = []\n",
    "# for integer, char in enumerate(chars,start=1):\n",
    "#     integer_to_char.append((integer,char))\n",
    "# integer_to_char = dict(integer_to_char)\n",
    "\n",
    "# #####################################################\n",
    "# # Assigning Numeric to all the values\n",
    "# len_input_NN = 30  #this determined the number of Input to the nueral network model\n",
    "# test_df[\"data_int\"]= \"\"\n",
    "\n",
    "# for i in range(0, (len(test_df.data))):\n",
    "#     data_chr_int =[0]*len_input_NN\n",
    "#     data_ = str(test_df.data[i])\n",
    "#     i_ = 0 \n",
    "#     for char in data_:\n",
    "#         data_chr_int[i_] = char_to_integer[char]\n",
    "#         if i_ >= len_input_NN-1:\n",
    "#             break\n",
    "#         i_+=1\n",
    "#     test_df[\"data_int\"][i] = data_chr_int\n",
    "    \n",
    "    \n",
    "# #####################################################\n",
    "# # Assigning the category to index and index to category for predicting the category in future using index\n",
    "# result_char = (list(set(test_df.result)))\n",
    "# cat_to_integer = []\n",
    "# integer_to_cat = []\n",
    "\n",
    "# for integer, char in enumerate(result_char,start=0):\n",
    "#     cat_to_integer.append((char, integer))\n",
    "# cat_to_integer = dict(cat_to_integer)\n",
    "\n",
    "# for integer, char in enumerate(result_char,start=0):\n",
    "#     integer_to_cat.append((integer, char))\n",
    "# integer_to_cat = dict(integer_to_cat)\n",
    "\n",
    "# test_df[\"result_int\"] = \"\"\n",
    "# for i in range(0, (len(test_df.result))):\n",
    "#     test_df[\"result_int\"][i] = cat_to_integer[test_df['result'][i]]\n",
    "     \n",
    "    \n",
    "# #####################################################\n",
    "# # Preparing the data for the Nueral Network model \n",
    "# X_train =[]\n",
    "\n",
    "# for i in test_df.data_int:\n",
    "#     X_train.append(i)\n",
    "    \n",
    "# # Reshape X_train and normalize\n",
    "# X_train = np.reshape(X_train, (len(X_train), len_input_NN, 1)) \n",
    "# X_train = X_train/float(len(chars))\n",
    "# y_train = np_utils.to_categorical(test_df.result_int)\n",
    "\n",
    "\n",
    "# #####################################################\n",
    "# # Model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape = (X_train.shape[1], X_train.shape[2]))) # 256 hidden nodes\n",
    "# model.add(Dropout(0.2))#This technique is applied in the training phase to reduce overfitting effects.# https://www.python-course.eu/neural_networks_with_dropout.php\n",
    "# model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
    "# # model.summary()\n",
    "\n",
    "# model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs = 100, batch_size = 100)\n",
    "\n",
    "# ######################################################\n",
    "# # Saving the model \n",
    "# pickle_op_dict = dict()\n",
    "# pickle_op_dict['char_to_integer']= char_to_integer\n",
    "# pickle_op_dict['integer_to_char']= integer_to_char\n",
    "# pickle_op_dict['chars']          = chars\n",
    "# pickle_op_dict['len_input_NN']   = len_input_NN\n",
    "# pickle_op_dict['integer_to_cat'] = integer_to_cat\n",
    "# pickle_op_dict['cat_to_integer'] = cat_to_integer\n",
    "\n",
    "# pickle_dict = 'ML_LCT_'+type_+'_dict.pkl'\n",
    "# pickle_out = open(pickle_dict,\"wb\")\n",
    "# pickle.dump(pickle_op_dict, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# model_file= 'ML_LCT_'+type_+'_Model.h5'\n",
    "# model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_sequence = generate_random_sequence()\n",
    "# # print(random_sequence)\n",
    "# generate_output_sequence(random_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_input = np.reshape(random_sequence, (1, len(input_sequence), 1))\n",
    "# y_pred = model.predict(X_input, verbose=0)\n",
    "# # y_pred\n",
    "\n",
    "# index = np.argmax(y_pred)\n",
    "# print(index,integer_to_cat[index])\n",
    "# # integer_to_cat[index],integer_to_cat[index],integer_to_cat[index+1],index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # dataframe_ = []\n",
    "# data = [['test1','test1','test1']]\n",
    "# dataframe_ = pd.DataFrame([],columns=['index','value','column'])\n",
    "# dataframe_\n",
    "# for index,i in enumerate(y_pred[0],start=0):\n",
    "# #     if index == 54:\n",
    "# #         break\n",
    "#     data = {'index':index,'value':round(i*100,2),'column':integer_to_cat[index]}\n",
    "#     dataframe_ = dataframe_.append(data,ignore_index=True)    \n",
    "\n",
    "# dataframe_.sort_values(by=['value'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" i am in connection database start\")\n",
    "# import psycopg2\n",
    "# conn = psycopg2.connect(\"dbname=postgres user=postgres password=Msjobs@123\")\n",
    "\n",
    "# def select_data(type_):\n",
    "#     cur = conn.cursor()\n",
    "#     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ ='\" +type_+\"';\"\n",
    "# #     sql_command = \"select value_,key_ from public.lct_ml_key_value where type_ = 'location';\"\n",
    "#     data = pd.read_sql(sql_command, conn)\n",
    "#     conn.commit()\n",
    "#     cur.close()\n",
    "#     return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
